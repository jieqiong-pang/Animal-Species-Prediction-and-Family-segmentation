{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=6 face=雅黑>2.K-Means Clustering on a Multi-Class and Multi-Label Data Set</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=5 face=雅黑>import package</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:44:07.569619Z",
     "start_time": "2019-11-07T00:44:07.192015Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=5 face=雅黑>(a)use k-means clustering on whole data set, and choose k based on Calinshi Harabaz</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:45:22.981225Z",
     "start_time": "2019-11-07T00:44:07.573276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.3788851472047738\n",
      "best k: 4\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('Frogs_MFCCs.csv')\n",
    "x=df.iloc[:,:-4]\n",
    "\n",
    "best_score=0\n",
    "\n",
    "for k in range(2,51):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(x)\n",
    "    pred = kmeans.predict(x)\n",
    "    score=silhouette_score(x, pred)\n",
    "    if score>best_score:\n",
    "        best_score=score\n",
    "        best_k=k\n",
    "print('best score:',best_score)\n",
    "print('best k:',best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=5 face=雅黑>(b)in each cluster,determine which family,genus,and species is the majority</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:45:23.104809Z",
     "start_time": "2019-11-07T00:45:22.982785Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = best_k).fit(x)\n",
    "labels = kmeans.labels_\n",
    "cluster_label = pd.DataFrame(labels, columns = [\"cluster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑> Family</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:45:23.131099Z",
     "start_time": "2019-11-07T00:45:23.108322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 4 cluster\n",
      "In cluster 0 , Leptodactylidae is the majority class\n",
      "In cluster 1 , Dendrobatidae is the majority class\n",
      "In cluster 2 , Hylidae is the majority class\n",
      "In cluster 3 , Hylidae is the majority class\n"
     ]
    }
   ],
   "source": [
    "tmp_Family = pd.concat([x, cluster_label, df['Family']], axis = 1)\n",
    "print('In',best_k,'cluster')\n",
    "for each_cluster in set(tmp_Family[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat---set([0,1])\n",
    "    value_count=tmp_Family[tmp_Family[\"cluster\"] == each_cluster]['Family'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    print('In cluster',each_cluster,',',majority_class,'is the majority class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑> Genus</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:45:23.158009Z",
     "start_time": "2019-11-07T00:45:23.134710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 4 cluster\n",
      "In cluster 0 , Adenomera is the majority class\n",
      "In cluster 1 , Ameerega is the majority class\n",
      "In cluster 2 , Hypsiboas is the majority class\n",
      "In cluster 3 , Hypsiboas is the majority class\n"
     ]
    }
   ],
   "source": [
    "tmp_Genus = pd.concat([x, cluster_label, df['Genus']], axis = 1)\n",
    "print('In',best_k,'cluster')\n",
    "for each_cluster in set(tmp_Genus[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Genus[tmp_Genus[\"cluster\"] == each_cluster]['Genus'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    print('In cluster',each_cluster,',',majority_class,'is the majority class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑> Species</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:45:23.189432Z",
     "start_time": "2019-11-07T00:45:23.160034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 4 cluster\n",
      "In cluster 0 , AdenomeraHylaedactylus is the majority class\n",
      "In cluster 1 , Ameeregatrivittata is the majority class\n",
      "In cluster 2 , HypsiboasCordobae is the majority class\n",
      "In cluster 3 , HypsiboasCinerascens is the majority class\n"
     ]
    }
   ],
   "source": [
    "tmp_Species = pd.concat([x, cluster_label, df['Species']], axis = 1)\n",
    "print('In',best_k,'cluster')\n",
    "for each_cluster in set(tmp_Species[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Species[tmp_Species[\"cluster\"] == each_cluster]['Species'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    print('In cluster',each_cluster,',',majority_class,'is the majority class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=5 face=雅黑>(c)for each cluster,calculate the average Hamming distance, Hamming score, Hamming loss</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑> Hamming distance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:45:23.277232Z",
     "start_time": "2019-11-07T00:45:23.202584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family hamming distance: 0.2785267546907575\n",
      "Genus hamming distance: 0.35802640722724116\n",
      "Species hamming distance: 0.5189715079916609\n",
      "Average hamming distance in 4 clusters is 0.3851748899698865\n"
     ]
    }
   ],
   "source": [
    "#Family\n",
    "tmp_Family = pd.concat([x, cluster_label, df['Family']], axis = 1)\n",
    "cluster_name_ls=[]\n",
    "for each_cluster in set(tmp_Family[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Family[tmp_Family[\"cluster\"] == each_cluster]['Family'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    for i in range(len(tmp_Family[tmp_Family[\"cluster\"] == each_cluster]['Family'])):\n",
    "        cluster_name_ls.append(majority_class)\n",
    "hamming_distance_Family=distance.hamming(cluster_name_ls, tmp_Family['Family'])\n",
    "print('Family hamming distance:',hamming_distance_Family)\n",
    "\n",
    "#Genus\n",
    "tmp_Genus = pd.concat([x, cluster_label, df['Genus']], axis = 1)\n",
    "cluster_name_ls=[]\n",
    "for each_cluster in set(tmp_Genus[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Genus[tmp_Genus[\"cluster\"] == each_cluster]['Genus'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    for i in range(len(tmp_Genus[tmp_Genus[\"cluster\"] == each_cluster]['Genus'])):\n",
    "        cluster_name_ls.append(majority_class)\n",
    "hamming_distance_Genus=distance.hamming(cluster_name_ls, tmp_Genus['Genus'])\n",
    "print('Genus hamming distance:',hamming_distance_Genus)\n",
    "\n",
    "#Species\n",
    "tmp_Species = pd.concat([x, cluster_label, df['Species']], axis = 1)\n",
    "cluster_name_ls=[]\n",
    "for each_cluster in set(tmp_Species[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Species[tmp_Species[\"cluster\"] == each_cluster]['Species'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    for i in range(len(tmp_Species[tmp_Species[\"cluster\"] == each_cluster]['Species'])):\n",
    "        cluster_name_ls.append(majority_class)\n",
    "hamming_distance_Species=distance.hamming(cluster_name_ls, tmp_Species['Species'])\n",
    "print('Species hamming distance:',hamming_distance_Species)\n",
    "\n",
    "avg_hamming_distance=np.mean([hamming_distance_Family, hamming_distance_Genus, hamming_distance_Species])\n",
    "print('Average hamming distance in',best_k,'clusters is',avg_hamming_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑> Hamming score</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:45:23.390366Z",
     "start_time": "2019-11-07T00:45:23.278685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family hamming score: 0.7214732453092425\n",
      "Genus hamming loss: 0.6419735927727589\n",
      "Species hamming loss: 0.48102849200833914\n",
      "Average hamming score in 4 clusters is 0.6148251100301135\n"
     ]
    }
   ],
   "source": [
    "#Family\n",
    "tmp_Family = pd.concat([x, cluster_label, df['Family']], axis = 1)\n",
    "cluster_name_ls=[]\n",
    "for each_cluster in set(tmp_Family[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Family[tmp_Family[\"cluster\"] == each_cluster]['Family'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    for i in range(len(tmp_Family[tmp_Family[\"cluster\"] == each_cluster]['Family'])):\n",
    "        cluster_name_ls.append(majority_class)\n",
    "hamming_score_Family=accuracy_score(tmp_Family['Family'],cluster_name_ls)\n",
    "print('Family hamming score:',hamming_score_Family)\n",
    "\n",
    "#Genus\n",
    "tmp_Genus = pd.concat([x, cluster_label, df['Genus']], axis = 1)\n",
    "cluster_name_ls=[]\n",
    "for each_cluster in set(tmp_Genus[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Genus[tmp_Genus[\"cluster\"] == each_cluster]['Genus'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    for i in range(len(tmp_Genus[tmp_Genus[\"cluster\"] == each_cluster]['Genus'])):\n",
    "        cluster_name_ls.append(majority_class)\n",
    "hamming_score_Genus=accuracy_score(tmp_Genus['Genus'],cluster_name_ls)\n",
    "print('Genus hamming loss:',hamming_score_Genus)\n",
    "\n",
    "#Species\n",
    "tmp_Species = pd.concat([x, cluster_label, df['Species']], axis = 1)\n",
    "cluster_name_ls=[]\n",
    "for each_cluster in set(tmp_Species[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Species[tmp_Species[\"cluster\"] == each_cluster]['Species'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    for i in range(len(tmp_Species[tmp_Species[\"cluster\"] == each_cluster]['Species'])):\n",
    "        cluster_name_ls.append(majority_class)\n",
    "hamming_score_Species=accuracy_score(tmp_Species['Species'],cluster_name_ls)\n",
    "print('Species hamming loss:',hamming_score_Species)\n",
    "\n",
    "avg_hamming_score=np.mean([hamming_score_Family, hamming_score_Genus, hamming_score_Species])\n",
    "print('Average hamming score in',best_k,'clusters is',avg_hamming_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑> Hamming loss</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:45:23.484422Z",
     "start_time": "2019-11-07T00:45:23.392472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family hamming loss: 0.2785267546907575\n",
      "Genus hamming loss: 0.35802640722724116\n",
      "Species hamming loss: 0.5189715079916609\n",
      "Average hamming loss in 4 clusters is 0.3851748899698865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "#Family\n",
    "tmp_Family = pd.concat([x, cluster_label, df['Family']], axis = 1)\n",
    "cluster_name_ls=[]\n",
    "for each_cluster in set(tmp_Family[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Family[tmp_Family[\"cluster\"] == each_cluster]['Family'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    for i in range(len(tmp_Family[tmp_Family[\"cluster\"] == each_cluster]['Family'])):\n",
    "        cluster_name_ls.append(majority_class)\n",
    "hamming_loss_Family=hamming_loss(tmp_Family['Family'],cluster_name_ls)\n",
    "print('Family hamming loss:',hamming_loss_Family)\n",
    "\n",
    "#Genus\n",
    "tmp_Genus = pd.concat([x, cluster_label, df['Genus']], axis = 1)\n",
    "cluster_name_ls=[]\n",
    "for each_cluster in set(tmp_Genus[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Genus[tmp_Genus[\"cluster\"] == each_cluster]['Genus'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    for i in range(len(tmp_Genus[tmp_Genus[\"cluster\"] == each_cluster]['Genus'])):\n",
    "        cluster_name_ls.append(majority_class)\n",
    "hamming_loss_Genus=hamming_loss(tmp_Genus['Genus'],cluster_name_ls)\n",
    "print('Genus hamming loss:',hamming_loss_Genus)\n",
    "\n",
    "#Species\n",
    "tmp_Species = pd.concat([x, cluster_label, df['Species']], axis = 1)\n",
    "cluster_name_ls=[]\n",
    "for each_cluster in set(tmp_Species[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "    value_count=tmp_Species[tmp_Species[\"cluster\"] == each_cluster]['Species'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "    majority_class=value_count.index[0]\n",
    "    for i in range(len(tmp_Species[tmp_Species[\"cluster\"] == each_cluster]['Species'])):\n",
    "        cluster_name_ls.append(majority_class)\n",
    "hamming_loss_Species=hamming_loss(tmp_Species['Species'],cluster_name_ls)\n",
    "print('Species hamming loss:',hamming_loss_Species)\n",
    "\n",
    "avg_hamming_loss=np.mean([hamming_loss_Family, hamming_loss_Genus, hamming_loss_Species])\n",
    "print('Average hamming loss in',best_k,'clusters is',avg_hamming_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=5 face=雅黑>Monte-Carlo Simulation, procedures 50 times, calculate average and standard hamming distance,score,loss</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T00:45:33.948386Z",
     "start_time": "2019-11-07T00:45:23.486143Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 times average hamming distance: 0.43384479962937234\n",
      "50 times standard hamming distance: 0.16023482371723208\n",
      "50 times average hamming score: 0.5661552003706278\n",
      "50 times standard hamming score: 0.16023482371723208\n",
      "50 times average hamming loss: 0.43384479962937234\n",
      "50 times standard hamming loss: 0.16023482371723208\n"
     ]
    }
   ],
   "source": [
    "hamming_distance_ls=[]\n",
    "hamming_score_ls=[]\n",
    "hamming_loss_ls=[]\n",
    "\n",
    "for times in range(0,50):\n",
    "    kmeans = KMeans(n_clusters = best_k).fit(x)\n",
    "    labels = kmeans.labels_\n",
    "    cluster_label = pd.DataFrame(labels, columns = [\"cluster\"])\n",
    "\n",
    "    #Family\n",
    "    tmp_Family = pd.concat([x, cluster_label, df['Family']], axis = 1)\n",
    "    cluster_name_ls=[]\n",
    "    for each_cluster in set(tmp_Family[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "        value_count=tmp_Family[tmp_Family[\"cluster\"] == each_cluster]['Family'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "        majority_class=value_count.index[0]\n",
    "        for i in range(len(tmp_Family[tmp_Family[\"cluster\"] == each_cluster]['Family'])):\n",
    "            cluster_name_ls.append(majority_class)\n",
    "    hamming_distance_Family=distance.hamming(cluster_name_ls, tmp_Family['Family'])\n",
    "    hamming_score_Family=accuracy_score(tmp_Family['Family'],cluster_name_ls)\n",
    "    hamming_loss_Family=hamming_loss(tmp_Family['Family'],cluster_name_ls)\n",
    "               \n",
    "    #Genus\n",
    "    tmp_Genus = pd.concat([x, cluster_label, df['Genus']], axis = 1)\n",
    "    cluster_name_ls=[]\n",
    "    for each_cluster in set(tmp_Genus[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "        value_count=tmp_Genus[tmp_Genus[\"cluster\"] == each_cluster]['Genus'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "        majority_class=value_count.index[0]\n",
    "        for i in range(len(tmp_Genus[tmp_Genus[\"cluster\"] == each_cluster]['Genus'])):\n",
    "            cluster_name_ls.append(majority_class)\n",
    "    hamming_distance_Genus=distance.hamming(cluster_name_ls, tmp_Genus['Genus'])\n",
    "    hamming_score_Genus=accuracy_score(tmp_Genus['Genus'],cluster_name_ls)\n",
    "    hamming_loss_Genus=hamming_loss(tmp_Genus['Genus'],cluster_name_ls)\n",
    "      \n",
    "    #Species\n",
    "    tmp_Species = pd.concat([x, cluster_label, df['Species']], axis = 1)\n",
    "    cluster_name_ls=[]\n",
    "    for each_cluster in set(tmp_Species[\"cluster\"]): # each cluster  #set：a list without order and cannot repeat\n",
    "        value_count=tmp_Species[tmp_Species[\"cluster\"] == each_cluster]['Species'].value_counts() #.value_counts(many different values there are in a column of a table and calculate how many duplicate values each different value has in that column\n",
    "        majority_class=value_count.index[0]\n",
    "        for i in range(len(tmp_Species[tmp_Species[\"cluster\"] == each_cluster]['Species'])):\n",
    "            cluster_name_ls.append(majority_class)\n",
    "    hamming_distance_Species=distance.hamming(cluster_name_ls, tmp_Species['Species'])\n",
    "    hamming_score_Species=accuracy_score(tmp_Species['Species'],cluster_name_ls)\n",
    "    hamming_loss_Species=hamming_loss(tmp_Species['Species'],cluster_name_ls)\n",
    "    \n",
    "    avg_hamming_distance=np.mean([hamming_distance_Family, hamming_distance_Genus, hamming_distance_Species])\n",
    "    hamming_distance_ls.append(avg_hamming_distance)\n",
    "    \n",
    "    avg_hamming_score=np.mean([hamming_score_Family, hamming_score_Genus, hamming_score_Species])\n",
    "    hamming_score_ls.append(avg_hamming_score)\n",
    "    \n",
    "    avg_hamming_loss=np.mean([hamming_loss_Family, hamming_loss_Genus, hamming_loss_Species])\n",
    "    hamming_loss_ls.append(avg_hamming_loss)\n",
    "\n",
    "print('50 times average hamming distance:',np.mean(hamming_distance_ls))\n",
    "print('50 times standard hamming distance:',np.std(hamming_distance_ls))\n",
    "\n",
    "print('50 times average hamming score:',np.mean(hamming_score_ls))\n",
    "print('50 times standard hamming score:',np.std(hamming_score_ls))\n",
    "\n",
    "print('50 times average hamming loss:',np.mean(hamming_loss_ls))\n",
    "print('50 times standard hamming loss:',np.std(hamming_loss_ls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
